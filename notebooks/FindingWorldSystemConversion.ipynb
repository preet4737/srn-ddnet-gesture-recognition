{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "regular-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "japanese-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_world_path = lambda g,f,s,e: f\"./gesture_{g}/finger_{f}/subject_{s}/essai_{e}/skeletons_world.txt\"\n",
    "get_image_path = lambda g,f,s,e: f\"./gesture_{g}/finger_{f}/subject_{s}/essai_{e}/skeletons_image.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "known-phase",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.loadtxt('./train_gestures.txt', dtype=np.uint16)\n",
    "test  = np.loadtxt('./test_gestures.txt',  dtype=np.uint16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-doubt",
   "metadata": {},
   "source": [
    "# Coordinate Systems\n",
    "\n",
    "There are 4 coordinate systems.\n",
    "\n",
    "- *Pixel coordinates* $(u, v)$ - Origin at top left of image\n",
    "- *Film coordinates* $(x, y)$ - Origin at $(c_x, c_y)$\n",
    "- *Camera coordinates* $(X_c, Y_c, Z_c)$ - Transform Film coordinates using intrinsics matrix $K$\n",
    "- *World coordinates* $(X_w, Y_w, Z_w)$ - Arbitrary world system, transform camera by extrinsics matrix $[R | t]$\n",
    "\n",
    "![](./pinhole_camera_model.png)\n",
    "\n",
    "http://www.cse.psu.edu/~rtc12/CSE486/lecture12.pdf\n",
    "\n",
    "https://docs.opencv.org/master/d9/d0c/group__calib3d.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-barrier",
   "metadata": {},
   "source": [
    "## Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-underwear",
   "metadata": {},
   "source": [
    "### Pixel to Film\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} u \\\\ v \\\\ 1 \\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} 1 & 0 & c_x \\\\ 0 & 1 & c_y \\\\ 0 & 0 & 1 \\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-preliminary",
   "metadata": {},
   "source": [
    "### Pixel to Camera\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} u \\\\ v \\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} f_x \\frac{X_c}{Z_c} + c_x \\\\ f_y \\frac{Y_c}{Z_c} + c_y \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-cruise",
   "metadata": {},
   "source": [
    "### Pixel to World\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} u \\\\ v \\\\ 1 \\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} f_x & 0 & c_x \\\\ 0 & f_y & c_y \\\\ 0 & 0 & 1 \\end{bmatrix}\n",
    "\\begin{bmatrix} R_{1x3} & t_{3x1} \\\\ 0_{1x3} & 1 \\end{bmatrix}\n",
    "\\begin{bmatrix} X_w \\\\ Y_w \\\\ Z_w \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-revolution",
   "metadata": {},
   "source": [
    "## Equations for Regression\n",
    "\n",
    "### Assumptions Case 1\n",
    "\n",
    "Let's assume `skeletons_world.txt` provides camera coordinates.\n",
    "\n",
    "The relation between pixel coordinates $(u,v)$ and camera coordinates $(X_c,Y_c,Z_c)$ is given by:\n",
    "$$u = f_x \\frac{X_c}{Z_c} + c_x$$\n",
    "$$v = f_y \\frac{Y_c}{Z_c} + c_y$$\n",
    "\n",
    "### Assumptions Case 2\n",
    "\n",
    "Let's assume `skeletons_world.txt` provides world coordinates.\n",
    "\n",
    "If we consider $M = K \\times [R|t]$, product of intrinsics $K$ and extrinsics $[R|t]$ matrix. Also assume that there's no rotation i.e. $R_{3xr} = I_{3x3}$, so $R$ is identity matrix. We want to find out the translation $t$ on camera polar center $(c_x, c_y)$ which is the origin of world coordinates.\n",
    "\n",
    "Then,\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} u \\\\ v \\\\ 1 \\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} f_x & 0 & c_x \\\\ 0 & f_y & c_y \\\\ 0 & 0 & 1 \\end{bmatrix}\n",
    "\\begin{bmatrix} I_{1x3} & t_{3x1} \\\\ 0_{1x3} & 1 \\end{bmatrix}\n",
    "\\begin{bmatrix} X_w \\\\ Y_w \\\\ Z_w \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} u \\\\ v \\\\ 1 \\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} f_x & 0 & c_x + t_x \\\\ 0 & f_y & c_y + t_y \\\\ 0 & 0 & 1 \\end{bmatrix}\n",
    "\\begin{bmatrix} X_w \\\\ Y_w \\\\ Z_w \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The equations are therefore,\n",
    "\n",
    "$$u = f_x \\frac{X_w}{Z_w} + (c_x + t_x)$$\n",
    "$$v = f_y \\frac{Y_w}{Z_w} + (c_y + t_y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-block",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "appropriate-excitement",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:31<00:00, 61.93it/s]\n"
     ]
    }
   ],
   "source": [
    "train_skeletons_world = []\n",
    "train_skeletons_image = []\n",
    "\n",
    "for g, f, s, e, start, end, num in tqdm(train):\n",
    "    xyz = np.loadtxt(get_world_path(g, f, s, e), dtype=np.float32)\n",
    "    xyz = np.reshape(xyz, (-1,22,3))\n",
    "    train_skeletons_world.append(xyz)\n",
    "    \n",
    "    uv  = np.loadtxt(get_image_path(g, f, s, e), dtype=np.float32)\n",
    "    uv  = np.reshape(uv,  (-1,22,2))\n",
    "    train_skeletons_image.append(uv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "seven-neutral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2535632, 3), (2535632, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_skeletons_world = np.concatenate(train_skeletons_world).reshape((-1, 3))\n",
    "train_skeletons_image = np.concatenate(train_skeletons_image).reshape((-1, 2))\n",
    "train_skeletons_world.shape, train_skeletons_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-arthritis",
   "metadata": {},
   "source": [
    "## U and X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "constant-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "XbyZ = train_skeletons_world[:,0]/train_skeletons_world[:,2]\n",
    "U = train_skeletons_image[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "empty-intervention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fx =  440.44232 cx =  -0.00015258789\n"
     ]
    }
   ],
   "source": [
    "regx = LinearRegression().fit(XbyZ[:,None], U[:,None])\n",
    "fx = regx.coef_[0][0]\n",
    "cx = regx.intercept_[0]\n",
    "print(\"fx = \", fx, \"cx = \", cx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-pepper",
   "metadata": {},
   "source": [
    "## V and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "technological-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "YbyZ = train_skeletons_world[:,1]/train_skeletons_world[:,2]\n",
    "V = train_skeletons_image[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "literary-church",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fy =  -461.0357 cx =  3.0517578e-05\n"
     ]
    }
   ],
   "source": [
    "regy = LinearRegression().fit(YbyZ[:,None], V[:,None])\n",
    "fy = regy.coef_[0][0]\n",
    "cy = regy.intercept_[0]\n",
    "print(\"fy = \", fy, \"cx = \", cy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-directory",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "partial-light",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 840/840 [00:13<00:00, 62.63it/s]\n"
     ]
    }
   ],
   "source": [
    "test_skeletons_world = []\n",
    "test_skeletons_image = []\n",
    "\n",
    "for g, f, s, e, start, end, num in tqdm(test):\n",
    "    xyz = np.loadtxt(get_world_path(g, f, s, e), dtype=np.float32)\n",
    "    xyz = np.reshape(xyz, (-1,22,3))\n",
    "    test_skeletons_world.append(xyz)\n",
    "    \n",
    "    uv  = np.loadtxt(get_image_path(g, f, s, e), dtype=np.float32)\n",
    "    uv  = np.reshape(uv,  (-1,22,2))\n",
    "    test_skeletons_image.append(uv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "clean-colonial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1093686, 3), (1093686, 2))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_skeletons_world = np.concatenate(test_skeletons_world).reshape((-1, 3))\n",
    "test_skeletons_image = np.concatenate(test_skeletons_image).reshape((-1, 2))\n",
    "test_skeletons_world.shape, test_skeletons_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-ladder",
   "metadata": {},
   "source": [
    "## U and X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "alike-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "XbyZ = test_skeletons_world[:,0]/test_skeletons_world[:,2]\n",
    "U = test_skeletons_image[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ancient-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_U = regx.predict(XbyZ[:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "outdoor-therapist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.185125e-05"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(U, pred_U)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-hypothesis",
   "metadata": {},
   "source": [
    "## V and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "computational-mouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "YbyZ = test_skeletons_world[:,1]/test_skeletons_world[:,2]\n",
    "V = test_skeletons_image[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "behavioral-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_V = regy.predict(YbyZ[:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "renewable-advocacy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.794273e-05"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(V, pred_V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-damages",
   "metadata": {},
   "source": [
    "# Final values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "developed-print",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440.44232, -461.0357, -0.00015258789, 3.0517578e-05)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fx, fy, cx, cy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-legislature",
   "metadata": {},
   "source": [
    "Note how $(c_x, c_y)$ are so close to zero that we can just consider them as zero. However, camera principal point should be close to center of image (not exactly center of image). Hence, `skeletons_world.txt` cannot be camera coordinates. There's some translation done to shift the world origin back to $(0, 0)$ to align the world with pixel coordinate system's origin at top left of the image. This translation is $c + t = 0$, hence $t = -c$.\n",
    "\n",
    "This implies `skeletons_world.txt` has origin aligned with that of pixel coordinate system of `skeletons_image.txt`, hence the values of $(c_x, c_y)$ are not to be used for shifting the origin and we can directly find world coordinates from pixel coordinates using:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} u \\\\ v \\\\ 1 \\end{bmatrix}\n",
    "=\n",
    "M\n",
    "\\begin{bmatrix} X_w \\\\ Y_w \\\\ Z_w \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Where\n",
    "$$\n",
    "M = K \\times [R|t]\n",
    "=\n",
    "\\begin{bmatrix} f_x & 0 & 0 \\\\ 0 & f_y & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-landscape",
   "metadata": {},
   "source": [
    "## Let's test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-environment",
   "metadata": {},
   "source": [
    "### World to image\n",
    "\n",
    "$$image = f \\frac{world}{Z_{world}}$$\n",
    "neglecting $c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "formed-dividend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([367.82114, 365.58813, 350.73312, ..., 363.6523 , 359.87857,\n",
       "       356.39206], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_image_x = test_skeletons_image[:,0]\n",
    "true_image_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "awful-float",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([367.8212 , 365.58823, 350.73322, ..., 363.65237, 359.87863,\n",
       "       356.39215], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_image_x = fx * test_skeletons_world[:,0] / test_skeletons_world[:,2]\n",
    "calc_image_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "anticipated-florida",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.117182e-05"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(true_image_x, calc_image_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "unavailable-prediction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([319.84595, 286.9815 , 311.01834, ..., 246.4431 , 237.16376,\n",
       "       228.7852 ], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_image_y = test_skeletons_image[:,1]\n",
    "true_image_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "distinguished-ending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([319.84592, 286.9815 , 311.01834, ..., 246.44308, 237.16376,\n",
       "       228.78519], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_image_y = fy * test_skeletons_world[:,1] / test_skeletons_world[:,2]\n",
    "calc_image_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "downtown-aurora",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.952551e-06"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(true_image_y, calc_image_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-blanket",
   "metadata": {},
   "source": [
    "### Image to World\n",
    "\n",
    "$$world = \\frac{image}{f} Z_{world}$$\n",
    "neglecting $c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "isolated-access",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49394462, 0.47372743, 0.45985433, ..., 0.39503437, 0.38705626,\n",
       "       0.37991765], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_world_x = test_skeletons_world[:,0]\n",
    "true_world_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "capable-andrew",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4939445 , 0.4737273 , 0.45985422, ..., 0.39503428, 0.38705617,\n",
       "       0.37991756], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_world_x = test_skeletons_image[:,0] / fx * test_skeletons_world[:,2]\n",
    "calc_world_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "returning-linux",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0257276e-07"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(true_world_x, calc_world_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fifteen-washer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([319.84595, 286.9815 , 311.01834, ..., 246.4431 , 237.16376,\n",
       "       228.7852 ], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_world_y = test_skeletons_image[:,1]\n",
    "true_world_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "standing-highlight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([319.84592, 286.9815 , 311.01834, ..., 246.44308, 237.16376,\n",
       "       228.78519], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_world_y = fy * test_skeletons_world[:,1] / test_skeletons_world[:,2]\n",
    "calc_world_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "hybrid-british",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.952551e-06"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(true_world_y, calc_world_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
